import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras import layers, models, Input


train_data_path = 'Facial_Images/train' 
val_data_path = 'Facial_Images/validation'


import os
x = 0
for expression in os.listdir(train_data_path):
    expression_path = os.path.join(train_data_path, expression)
    print(expression, "  ", len(os.listdir(expression_path)))
    x = x + len(os.listdir(expression_path))
print("Total Images", x)


emotions = []
x = 0
for expression in os.listdir(val_data_path):
    expression_path = os.path.join(val_data_path, expression)
    print(expression, "  ", len(os.listdir(expression_path)))
    data = [expression]
    x = x + len(os.listdir(expression_path))
    emotions.append(data)
print("Total Images", x)


emotions


i = 1
plt.figure(figsize=(8, 8))

for expression in os.listdir(train_data_path):
    image_path = os.path.join(train_data_path, expression, os.listdir(os.path.join(train_data_path, expression))[0])
    image = load_img(image_path)
    
    plt.subplot(1, 7, i)
    plt.imshow(image)
    plt.title(expression)
    plt.axis('off')
    i += 1



train_data_gen = ImageDataGenerator()

train_dataset = train_data_gen.flow_from_directory(
    train_data_path,
    shuffle=True,
    target_size=(48, 48),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=128
)


val_data_gen = ImageDataGenerator()

val_dataset = val_data_gen.flow_from_directory(
    val_data_path,
    shuffle=False,
    target_size=(48, 48),
    color_mode='grayscale',
    class_mode='categorical',
    batch_size=128
)


model = models.Sequential()

model.add(Input(shape=(48, 48, 1)))  # Explicit input layer

model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))
model.add(layers.BatchNormalization())
model.add(layers.MaxPooling2D(pool_size=(2, 2)))
model.add(layers.Dropout(0.25))

model.add(layers.Conv2D(128, (5, 5), padding='same', activation='relu'))
model.add(layers.BatchNormalization())
model.add(layers.MaxPooling2D(pool_size=(2, 2)))
model.add(layers.Dropout(0.25))

model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))
model.add(layers.BatchNormalization())
model.add(layers.MaxPooling2D(pool_size=(2, 2)))
model.add(layers.Dropout(0.25))

model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))
model.add(layers.BatchNormalization())
model.add(layers.MaxPooling2D(pool_size=(2, 2)))
model.add(layers.Dropout(0.25))

model.add(layers.Flatten())

model.add(layers.Dense(128))
model.add(layers.BatchNormalization())
model.add(layers.Activation('relu'))
model.add(layers.Dropout(0.25))

model.add(layers.Dense(256))
model.add(layers.BatchNormalization())
model.add(layers.Activation('relu'))
model.add(layers.Dropout(0.25))

model.add(layers.Dense(7, activation='softmax'))

model.summary()



model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=50,
    verbose=1
)


os.makedirs('models', exist_ok=True)


model.save('models/Face_Emotion_classification.keras')


import cv2


model = tf.keras.models.load_model('models/Face_Emotion_classification.keras')

image = cv2.imread('Google_Images/84.jpg', cv2.IMREAD_GRAYSCALE)
image = cv2.resize(image, (48, 48))
image = cv2.bitwise_not(image)
image = image.astype('float32') / 255.0
image = np.expand_dims(image, axis=(0, -1))

output = model.predict(image)
predicted_class = np.argmax(output)

emotion_labels = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']
print(f"Predicted Emotion: {emotion_labels[predicted_class]}")
